{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11206aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import requests\n",
    "import regex as re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ad679f",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83b46589",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_SOURCE = \"https://www.goodreads.com/\"\n",
    "URL_START = \"https://www.goodreads.com/list/tag/\"\n",
    "BOOK_CATEGORIES = [\n",
    "    \"romance\",\n",
    "    \"fiction\",\n",
    "    \"young-adult\",\n",
    "    \"fantasy\",\n",
    "    \"science-fiction\",\n",
    "    \"non-fiction\",\n",
    "    \"children\",\n",
    "    \"history\",\n",
    "    \"covers\",\n",
    "    \"mystery\",\n",
    "    \"horror\",\n",
    "    \"best\",\n",
    "    \"historical-fiction\",\n",
    "    \"gay\",\n",
    "    \"paranormal\",\n",
    "    \"love\",\n",
    "    \"titles\",\n",
    "    \"contemporary\",\n",
    "    \"middle-grade\",\n",
    "    \"historical-romance\",\n",
    "    \"biography\",\n",
    "    \"thriller\",\n",
    "    \"series\",\n",
    "    \"women\",\n",
    "    \"nonfiction\",\n",
    "    \"classics\",\n",
    "    \"lgbt\",\n",
    "    \"graphic-novels\",\n",
    "    \"memoir\",\n",
    "    \"queer\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e362f4",
   "metadata": {},
   "source": [
    "Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "042b723a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_body(url: str):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        print (\"http error:\",errh)\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        print (\"conection error:\",errc)\n",
    "    except requests.exceptions.Timeout as errt:\n",
    "        print (\"timeout error:\",errt)\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print (\"other error:\",err)\n",
    "        \n",
    "    if response.status_code == 200:\n",
    "        page = bs.BeautifulSoup(response.text)\n",
    "        return page.body\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def clean_text(s: str):\n",
    "    s = re.sub(r'[\\n\\t]', ' ', s)\n",
    "    s = s.strip()\n",
    "    s = ' '.join(s.split())\n",
    "    return s\n",
    "\n",
    "    \n",
    "def get_category_urls(input_url: str = URL_START, top_n:int = 1) -> dict:\n",
    "    category_urls = {}\n",
    "    for category in BOOK_CATEGORIES:\n",
    "        page_body = get_page_body(input_url + category)\n",
    "        if page_body:\n",
    "            link = page_body.find(\"div\",{\"class\": \"listImgs\"}).find(\"a\")['href']\n",
    "            links = [\"https://www.goodreads.com/\" + link + f\"?page={i}\" for i in range(1,top_n+1)]\n",
    "            category_urls[category] = links\n",
    "    return category_urls\n",
    "\n",
    "\n",
    "def get_separate_book_urls(url: str):\n",
    "    page_body = get_page_body(url)\n",
    "    urls = []\n",
    "    if page_body:\n",
    "        for section in page_body.find_all(\"a\",{\"class\": \"bookTitle\"}):\n",
    "            link = URL_SOURCE + section['href']\n",
    "            urls.append(link)\n",
    "    return urls\n",
    "\n",
    "\n",
    "def get_text(x):\n",
    "    return clean_text(getattr(x, \"text\", \"\"))\n",
    "\n",
    "\n",
    "def get_book_info(url: str, book_category: str):\n",
    "    page_body = get_page_body(url)\n",
    "    book_info = {}\n",
    "    if page_body:\n",
    "        book_info[\"category\"] = book_category\n",
    "        book_info[\"title\"] = get_text(page_body.find(\"h1\", id = \"bookTitle\"))\n",
    "        book_info[\"author\"] = get_text(page_body.find(\"span\", itemprop=\"name\"))\n",
    "        book_info[\"description\"] = get_text(page_body.find(\"div\", id=\"description\"))\n",
    "        book_info[\"rating\"] =  get_text(page_body.find(\"span\", itemprop=\"ratingValue\"))\n",
    "        book_info[\"number_of_pages\"] = get_text(page_body.find(\"span\", itemprop=\"numberOfPages\"))\n",
    "        book_info[\"url\"] = url\n",
    "    return book_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9ff0c7",
   "metadata": {},
   "source": [
    "Main scraping script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "653eb0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_db = pd.DataFrame()\n",
    "category_urls = get_category_urls()\n",
    "\n",
    "for category in category_urls.keys():\n",
    "    if category_urls[category]:\n",
    "        for page_url in category_urls[category]:\n",
    "            books_urls_list = get_separate_book_urls(page_url)\n",
    "            if books_urls_list:\n",
    "                for book_url in books_urls_list:\n",
    "                    book_info = get_book_info(book_url, category)\n",
    "                    if book_info:\n",
    "                        books_db = books_db.append(book_info, ignore_index=True)\n",
    "books_db.to_parquet(\"books_info.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d671492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"books_info.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
